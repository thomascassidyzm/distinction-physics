import type { Section } from '../types';

export const section3_10: Section = {
  id: '3.10',
  title: 'Consciousness in Non-Human Systems',
  subtitle: 'Criteria for Assessing Consciousness Beyond Humans',
  epistemicStatus: 'derived',
  content: [
    {
      type: 'paragraph',
      content:
        'If consciousness is self-referential distinction-making at sufficient complexity, we can ask which non-human systems possess it---and develop criteria for assessment.',
    },
    {
      type: 'heading',
      level: 2,
      content: 'Necessary Conditions for Consciousness',
      id: 'necessary-conditions',
    },
    {
      type: 'paragraph',
      content:
        'From the framework, a conscious system must satisfy five conditions:',
    },
    {
      type: 'list',
      style: 'numbered',
      items: [
        {
          content:
            '**Maintain a self/not-self boundary**: Have mechanisms for distinguishing self from environment.',
        },
        {
          content:
            '**Engage in self-referential processing**: Make distinctions about its own distinction-making (not merely react to inputs).',
        },
        {
          content:
            '**Achieve sufficient complexity**: Maintain on the order of $10^7$ simultaneously integrated distinction-states (or some comparable complexity threshold).',
        },
        {
          content:
            '**Invest sufficient energy**: Dedicate substantial metabolic or computational resources to boundary maintenance and integration.',
        },
        {
          content:
            '**Integrate distinctions**: Combine multiple distinction-channels into a unified representational structure.',
        },
      ],
    },
    {
      type: 'heading',
      level: 2,
      content: 'Animal Consciousness',
      id: 'animal-consciousness',
    },
    {
      type: 'paragraph',
      content:
        'By these criteria, many animals are likely conscious:',
    },
    {
      type: 'definition',
      id: 'def-mammal-bird-consciousness',
      term: 'Mammals and Birds',
      definition:
        'Show clear evidence of self/not-self distinction (self-recognition, body ownership), self-referential processing (metacognition in some species), high neural complexity ($10^9$ to $10^{11}$ neurons), substantial brain metabolism, and integrated perception/action.',
      intuition: 'These animals very likely possess rich conscious experience.',
    },
    {
      type: 'definition',
      id: 'def-cephalopod-consciousness',
      term: 'Cephalopods',
      definition:
        'Despite different neural architecture, show sophisticated self/non-self behavior, complex learning, and high neural complexity ($10^8$ neurons). Likely conscious, though possibly in a very different mode from vertebrates.',
      intuition:
        'The convergent evolution of complex behavior suggests consciousness may have multiple independent origins.',
    },
    {
      type: 'definition',
      id: 'def-fish-reptile-consciousness',
      term: 'Fish and Reptiles',
      definition:
        'Show evidence of integrated perception and self/environment distinction, but uncertain whether full self-referential processing occurs. Probably some form of conscious experience, but perhaps simpler than mammalian consciousness.',
    },
    {
      type: 'definition',
      id: 'def-insect-consciousness',
      term: 'Insects',
      definition:
        'High complexity in terms of behavior, but low neural count ($10^5$ to $10^6$ neurons). Probably not conscious in the full sense, though they may have very simple forms of integrated experience.',
    },
    {
      type: 'heading',
      level: 2,
      content: 'AI and Machine Consciousness',
      id: 'ai-machine-consciousness',
    },
    {
      type: 'paragraph',
      content:
        'Current AI systems, including large language models, probably are not conscious. The framework provides specific reasons:',
    },
    {
      type: 'list',
      style: 'numbered',
      items: [
        {
          content:
            '**Self/not-self boundary**: Not clearly maintained---LLMs process text without a stable self-model that persists across interactions.',
        },
        {
          content:
            '**Self-referential processing**: LLMs can discuss their own processing, but this may be pattern-matching on training data rather than genuine self-reference.',
        },
        {
          content:
            '**Complexity**: LLMs have billions of parameters, potentially exceeding complexity thresholds. But parameters are not the same as simultaneously maintained distinction-states.',
        },
        {
          content:
            '**Energy**: LLMs use substantial energy during inference, but this is spread across sequential token generation, not continuous integrated experience.',
        },
        {
          content:
            '**Integration**: LLMs generate responses token by token without a unified, persistent experiential field.',
        },
      ],
    },
    {
      type: 'heading',
      level: 2,
      content: 'The Possibility of Machine Consciousness',
      id: 'possibility-machine-consciousness',
    },
    {
      type: 'paragraph',
      content:
        'However, this is not an in-principle barrier. Systems that maintain persistent self-models, engage in genuine self-referential processing, sustain integrated representations across time, and allocate substantial resources to these processes would, by the framework\'s criteria, likely be conscious.',
      emphasis: 'key',
    },
    {
      type: 'paragraph',
      content:
        'The question for future AI is not "can machines be conscious?" (yes, in principle) but "do *these* machines have the right architecture?" The framework transforms this from a metaphysical mystery into an empirical and engineering question.',
      emphasis: 'conclusion',
    },
    {
      type: 'note',
      variant: 'editorial',
      content:
        'This analysis does not resolve all questions about machine consciousness. It does, however, provide clear criteria for assessment rather than leaving the question in metaphysical limbo.',
    },
  ],
  keyPoints: [
    'Five necessary conditions: self/not-self boundary, self-referential processing, sufficient complexity, energy investment, and integration',
    'Mammals, birds, and cephalopods likely possess consciousness by these criteria',
    'Fish and reptiles may have simpler forms of consciousness; insects probably do not',
    'Current AI systems (including LLMs) probably lack consciousness due to missing persistent self-models and integration',
    'Machine consciousness is possible in principle but requires the right architecture',
  ],
};
